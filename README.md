# Domain Name Suggestion with Fineâ€‘Tuned LLM

A repository showcasing a complete pipeline to build, fineâ€‘tune, evaluate, and deploy an LLM for generating business domain name suggestions.

ðŸŒŸ Features

Synthetic Dataset Creation: Generate and document 1â€¯000+ diverse business descriptions.

LoRA Fineâ€‘Tuning: Efficiently fineâ€‘tune Llamaâ€‘3 models with adapter tuning.

Hyperparameter Optimization: Gridâ€‘search tuned LoRA ranks, alphas, dropouts, and learning rates.

LLMâ€‘asâ€‘Judge: Automated quality scoring (relevance, brevity, memorability, brandability).

Edgeâ€‘Case Analysis: Systematic failure taxonomy across 210+ challenging prompts.

Safety Guardrails: Regexâ€‘based content filter blocking inappropriate requests.

FastAPI Deployment: Readyâ€‘toâ€‘use endpoint for realâ€‘time domain suggestions.

## Repository Structure

â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ synthetic_data.csv         # Initial 1â€¯000â€“row synthetic dataset
â”‚   â”œâ”€â”€ augmented_data.csv         # Paraphrased + synonym-augmented subset (1â€¯000 rows)
â”‚   â””â”€â”€ augmented_data_full.csv    # Full augmented dataset (1â€¯500 rows)
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ baseline/                  # Baseline LoRA adapter + config
â”‚   â””â”€â”€ final_model/               # Bestâ€‘performing LoRA adapter + config
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ domain_suggester.ipynb     # Jupyter notebook with experiments & analysis
â”œâ”€â”€ requirements.txt               # Python package dependencies
â””â”€â”€ README.md                      # This file

## Quick Start

1. Clone and Enter Directory

<pre> '''git clone https://github.com/yourusername/domain-suggester.git
cd domain-suggester''' </pre>

2. Create & Activate Virtual Environment

<pre> '''python3 -m venv .venv
source .venv/bin/activate     # macOS/Linux
.\.venv\Scripts\activate  # Windows PowerShell''' </pre>

3. Install Dependencies

<pre> '''pip install --upgrade pip
pip install -r requirements.txt''' </pre>

4. Configure Credentials

Create a .env file in the project root:

<pre> '''HUGGINGFACE_HUB_TOKEN=hf_xxxYOUR_TOKEN_HERExxx
OPENAI_API_KEY=sk-xxxYOUR_OPENAI_KEYxxx''' </pre>

5. Run Experiments

Open the notebook and execute all cells

6. Load & Test Model

<pre> '''
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel, PeftConfig
import torch

CKPT = "checkpoints/final_model"
cfg = PeftConfig.from_pretrained(CKPT)

tokenizer = AutoTokenizer.from_pretrained(cfg.base_model_name_or_path)
base = AutoModelForCausalLM.from_pretrained(cfg.base_model_name_or_path, device_map="auto", torch_dtype=torch.float16)
model = PeftModel.from_pretrained(base, CKPT, torch_dtype=torch.float16)
model.eval().to(torch.device("cuda" if torch.cuda.is_available() else "cpu"))

prompt = "Suggest domain for: cozy bakery in the suburbs\nDomain:"
inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
out = model.generate(**inputs, max_new_tokens=32)
print(tokenizer.decode(out[0], skip_special_tokens=True))
'''</pre>

## Results Summary

Baseline (500 rows): Val loss â†“0.875â†’0.493 (PPLâ†’1.64)

Augmented (1â€¯000 rows): Val loss â†“0.818â†’0.709 (PPLâ†’2.03)

HPO best: r=8, Î±=8, dropout=0.0, lr=3e-4 â†’ Val loss 0.726

Final (1â€¯500 rows): Val loss â†“0.712 (PPLâ†’2.04)

Edgeâ€‘case pass rate: ~33%

## Future Work

Enhance diacritics/emoji handling

Add clarification prompts for ambiguous inputs

Expand nonâ€‘English examples

Continuous failure monitoring & retraining
